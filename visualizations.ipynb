{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "029d6c34-2fd2-4056-b83b-47615c93237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaredpc\\AppData\\Local\\Temp\\ipykernel_102508\\4199292568.py:63: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_test = pd.read_sql(test_query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples: 4472\n",
      "Using device: cuda\n",
      "================================================================================\n",
      "Processing model: Bio_ClinicalBERT\n",
      "================================================================================\n",
      "[Bio_ClinicalBERT] Loading baseline model...\n",
      "[Bio_ClinicalBERT] Computing baseline embeddings...\n",
      "Running t-SNE for Bio_ClinicalBERT – Baseline (No Contrastive) (N=2000)...\n",
      "Saved: ./tsne_figures\\Bio_ClinicalBERT_baseline_tsne.png\n",
      "[Bio_ClinicalBERT] Loading contrastive encoder...\n",
      "[Bio_ClinicalBERT] Computing contrastive embeddings...\n",
      "Running t-SNE for Bio_ClinicalBERT – With Contrastive Learning (N=2000)...\n",
      "Saved: ./tsne_figures\\Bio_ClinicalBERT_contrastive_tsne.png\n",
      "================================================================================\n",
      "Processing model: DeBERTa-v3-base\n",
      "================================================================================\n",
      "[DeBERTa-v3-base] Loading baseline model...\n",
      "[DeBERTa-v3-base] Computing baseline embeddings...\n",
      "Running t-SNE for DeBERTa-v3-base – Baseline (No Contrastive) (N=2000)...\n",
      "Saved: ./tsne_figures\\DeBERTa-v3-base_baseline_tsne.png\n",
      "[DeBERTa-v3-base] Loading contrastive encoder...\n",
      "[DeBERTa-v3-base] Computing contrastive embeddings...\n",
      "Running t-SNE for DeBERTa-v3-base – With Contrastive Learning (N=2000)...\n",
      "Saved: ./tsne_figures\\DeBERTa-v3-base_contrastive_tsne.png\n",
      "================================================================================\n",
      "Processing model: RadBERT\n",
      "================================================================================\n",
      "[RadBERT] Loading baseline model...\n",
      "[RadBERT] Computing baseline embeddings...\n",
      "Running t-SNE for RadBERT – Baseline (No Contrastive) (N=2000)...\n",
      "Saved: ./tsne_figures\\RadBERT_baseline_tsne.png\n",
      "[RadBERT] Loading contrastive encoder...\n",
      "[RadBERT] Computing contrastive embeddings...\n",
      "Running t-SNE for RadBERT – With Contrastive Learning (N=2000)...\n",
      "Saved: ./tsne_figures\\RadBERT_contrastive_tsne.png\n",
      "\n",
      "All t-SNE visualizations completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from databricks import sql\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "from sklearn.manifold import TSNE\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "MAX_TSNE_SAMPLES = 2000\n",
    "BATCH_SIZE = 32\n",
    "MAX_LENGTH = 120\n",
    "FIG_DIR = \"./tsne_figures\"\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "# Model + path config (matches your folder layout)\n",
    "MODEL_CONFIGS = {\n",
    "    \"Bio_ClinicalBERT\": {\n",
    "        \"tokenizer_path\": \"./trained_models/emilyalsentzer_Bio_ClinicalBERT_tokenizer\",\n",
    "        \"baseline_path\": \"./trained_models/emilyalsentzer_Bio_ClinicalBERT_baseline\",\n",
    "        \"contrastive_path\": \"./trained_models/emilyalsentzer_Bio_ClinicalBERT_contrastive_encoder\",\n",
    "        \"title_prefix\": \"Bio_ClinicalBERT\",\n",
    "    },\n",
    "    \"DeBERTa-v3-base\": {\n",
    "        \"tokenizer_path\": \"./trained_models/microsoft_deberta-v3-base_tokenizer\",\n",
    "        \"baseline_path\": \"./trained_models/microsoft_deberta-v3-base_baseline\",\n",
    "        \"contrastive_path\": \"./trained_models/microsoft_deberta-v3-base_contrastive_encoder\",\n",
    "        \"title_prefix\": \"DeBERTa-v3-base\",\n",
    "    },\n",
    "    \"RadBERT\": {\n",
    "        \"tokenizer_path\": \"./trained_models/zzxslp_RadBERT-RoBERTa-4m_tokenizer\",\n",
    "        \"baseline_path\": \"./trained_models/zzxslp_RadBERT-RoBERTa-4m_baseline\",\n",
    "        \"contrastive_path\": \"./trained_models/zzxslp_RadBERT-RoBERTa-4m_contrastive_encoder\",\n",
    "        \"title_prefix\": \"RadBERT\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# -----------------------\n",
    "# 1. Load test data\n",
    "# -----------------------\n",
    "load_dotenv()\n",
    "\n",
    "connection = sql.connect(\n",
    "    server_hostname=os.getenv(\"DATABRICKS_HOST\").replace(\"https://\", \"\").replace(\"http://\", \"\"),\n",
    "    http_path=\"/sql/1.0/warehouses/fe659a9780b351a1\",\n",
    "    access_token=os.getenv(\"DATABRICKS_TOKEN\"),\n",
    ")\n",
    "\n",
    "test_query = \"\"\"\n",
    "SELECT subject_id, study_id, findings, impression, label, confidence\n",
    "FROM workspace.default.mimic_cxr_test_set_label_explanation_consensus_v1\n",
    "WHERE findings IS NOT NULL\n",
    "  AND impression IS NOT NULL\n",
    "  AND label IN ('Normal', 'Abnormal')\n",
    "\"\"\"\n",
    "\n",
    "df_test = pd.read_sql(test_query, connection)\n",
    "connection.close()\n",
    "\n",
    "df_test[\"Context\"] = (df_test[\"findings\"].fillna(\"\") + \" \" +\n",
    "                      df_test[\"impression\"].fillna(\"\")).str.strip()\n",
    "label_map = {\"Normal\": 0, \"Abnormal\": 1}\n",
    "df_test[\"Result\"] = df_test[\"label\"].map(label_map)\n",
    "\n",
    "test_texts_full = df_test[\"Context\"].tolist()\n",
    "test_labels_full = df_test[\"Result\"].tolist()\n",
    "\n",
    "print(\"Total test samples:\", len(test_texts_full))\n",
    "\n",
    "# Use the same subset for all models\n",
    "texts = test_texts_full[:MAX_TSNE_SAMPLES]\n",
    "labels = test_labels_full[:MAX_TSNE_SAMPLES]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Helper: embeddings\n",
    "# -----------------------\n",
    "def get_sentence_embeddings(texts, labels, model, tokenizer, device,\n",
    "                            batch_size=BATCH_SIZE, max_length=MAX_LENGTH):\n",
    "    model.eval()\n",
    "\n",
    "    all_embs = []\n",
    "    all_labs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i + batch_size]\n",
    "            batch_labels = labels[i:i + batch_size]\n",
    "\n",
    "            enc = tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(device)\n",
    "\n",
    "            # We always request hidden_states to be safe across model types\n",
    "            outputs = model(**enc, output_hidden_states=True)\n",
    "\n",
    "            # For AutoModel / AutoModelForSequenceClassification both will have hidden_states\n",
    "            last_hidden = outputs.hidden_states[-1]  # [B, L, H]\n",
    "\n",
    "            # Masked mean pooling\n",
    "            mask = enc[\"attention_mask\"].unsqueeze(-1)  # [B, L, 1]\n",
    "            masked_hidden = last_hidden * mask\n",
    "            lengths = mask.sum(dim=1).clamp(min=1)      # [B, 1]\n",
    "            sent_emb = masked_hidden.sum(dim=1) / lengths  # [B, H]\n",
    "\n",
    "            all_embs.append(sent_emb.cpu())\n",
    "            all_labs.extend(batch_labels)\n",
    "\n",
    "    emb_tensor = torch.cat(all_embs, dim=0)  # [N, H]\n",
    "    emb_array = emb_tensor.numpy()\n",
    "    label_array = np.array(all_labs)\n",
    "    return emb_array, label_array\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Helper: run t-SNE + plot\n",
    "# -----------------------\n",
    "def tsne_and_save(emb_array, label_array, title, outfile):\n",
    "    print(f\"Running t-SNE for {title} (N={emb_array.shape[0]})...\")\n",
    "    tsne = TSNE(\n",
    "        n_components=3,\n",
    "        learning_rate=\"auto\",\n",
    "        init=\"random\",\n",
    "        perplexity=30,\n",
    "        random_state=42,\n",
    "    )\n",
    "    emb_3d = tsne.fit_transform(emb_array)  # [N, 3]\n",
    "\n",
    "    labels_np = label_array\n",
    "    normal_idx = labels_np == 0\n",
    "    abnormal_idx = labels_np == 1\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 7))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    ax.scatter(\n",
    "        emb_3d[normal_idx, 0],\n",
    "        emb_3d[normal_idx, 1],\n",
    "        emb_3d[normal_idx, 2],\n",
    "        alpha=0.6,\n",
    "        label=\"Normal (0)\",\n",
    "        s=10,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        emb_3d[abnormal_idx, 0],\n",
    "        emb_3d[abnormal_idx, 1],\n",
    "        emb_3d[abnormal_idx, 2],\n",
    "        alpha=0.6,\n",
    "        label=\"Abnormal (1)\",\n",
    "        marker=\"^\",\n",
    "        s=10,\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"t-SNE Dim 1\")\n",
    "    ax.set_ylabel(\"t-SNE Dim 2\")\n",
    "    ax.set_zlabel(\"t-SNE Dim 3\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outfile, dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {outfile}\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Main loop over models\n",
    "# -----------------------\n",
    "for model_key, cfg in MODEL_CONFIGS.items():\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Processing model: {model_key}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Shared tokenizer for baseline + contrastive\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        cfg[\"tokenizer_path\"],\n",
    "        use_fast=False\n",
    "    )\n",
    "\n",
    "    # ---------- Baseline ----------\n",
    "    print(f\"[{model_key}] Loading baseline model...\")\n",
    "    baseline_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        cfg[\"baseline_path\"],\n",
    "        local_files_only=True,\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"[{model_key}] Computing baseline embeddings...\")\n",
    "    emb_base, lab_base = get_sentence_embeddings(texts, labels, baseline_model, tokenizer, device)\n",
    "\n",
    "    base_title = f\"{cfg['title_prefix']} – Baseline (No Contrastive)\"\n",
    "    base_outfile = os.path.join(\n",
    "        FIG_DIR,\n",
    "        f\"{model_key.replace('/', '_').replace(' ', '_')}_baseline_tsne.png\",\n",
    "    )\n",
    "    tsne_and_save(emb_base, lab_base, base_title, base_outfile)\n",
    "\n",
    "    # ---------- Contrastive Encoder ----------\n",
    "    print(f\"[{model_key}] Loading contrastive encoder...\")\n",
    "    contrastive_model = AutoModel.from_pretrained(\n",
    "        cfg[\"contrastive_path\"],\n",
    "        local_files_only=True,\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"[{model_key}] Computing contrastive embeddings...\")\n",
    "    emb_con, lab_con = get_sentence_embeddings(texts, labels, contrastive_model, tokenizer, device)\n",
    "\n",
    "    con_title = f\"{cfg['title_prefix']} – With Contrastive Learning\"\n",
    "    con_outfile = os.path.join(\n",
    "        FIG_DIR,\n",
    "        f\"{model_key.replace('/', '_').replace(' ', '_')}_contrastive_tsne.png\",\n",
    "    )\n",
    "    tsne_and_save(emb_con, lab_con, con_title, con_outfile)\n",
    "\n",
    "print(\"\\nAll t-SNE visualizations completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bdd3204-9903-4bec-bba5-1242605a9e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unified figure saved to:\n",
      "./tsne_figures/unified_tsne_comparison.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FIG_DIR = \"./tsne_figures\"\n",
    "OUT_FILE = \"./tsne_figures/unified_tsne_comparison.png\"\n",
    "\n",
    "# Ordered layout (row-wise)\n",
    "IMAGE_ORDER = [\n",
    "    (\"Bio_ClinicalBERT_baseline_tsne.png\", \"BioBERT – No Contrastive\"),\n",
    "    (\"Bio_ClinicalBERT_contrastive_tsne.png\", \"BioBERT – With Contrastive\"),\n",
    "    (\"DeBERTa-v3-base_baseline_tsne.png\", \"DeBERTa – No Contrastive\"),\n",
    "    (\"DeBERTa-v3-base_contrastive_tsne.png\", \"DeBERTa – With Contrastive\"),\n",
    "    (\"RadBERT_baseline_tsne.png\", \"RadBERT – No Contrastive\"),\n",
    "    (\"RadBERT_contrastive_tsne.png\", \"RadBERT – With Contrastive\"),\n",
    "]\n",
    "\n",
    "# Load images\n",
    "images = []\n",
    "titles = []\n",
    "\n",
    "for fname, title in IMAGE_ORDER:\n",
    "    path = os.path.join(FIG_DIR, fname)\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Missing image: {path}\")\n",
    "    images.append(Image.open(path))\n",
    "    titles.append(title)\n",
    "\n",
    "# Create figure: 3 rows × 2 columns\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 22))\n",
    "\n",
    "for ax, img, title in zip(axes.flatten(), images, titles):\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Latent Space Visualization (t-SNE, Test Set)\\nBaseline vs Contrastive Learning\",\n",
    "    fontsize=20,\n",
    "    y=0.98,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.savefig(OUT_FILE, dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nUnified figure saved to:\\n{OUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493f42c7-9fee-436a-a338-8cba838a1115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained_model_metrics\\emilyalsentzer_Bio_ClinicalBERT_metrics.csv...\n",
      "Loading trained_model_metrics\\microsoft_deberta-v3-base_metrics.csv...\n",
      "Loading trained_model_metrics\\zzxslp_RadBERT-RoBERTa-4m_metrics.csv...\n",
      "\n",
      "Summary table:\n",
      "                       Model              Loss  accuracy  specificity  \\\n",
      "0  Bio_ClinicalBERT-document     baseline loss     95.59        92.52   \n",
      "1  Bio_ClinicalBERT-document  contrastive loss     95.48        94.56   \n",
      "2   DeBERTa-v3-base-document     baseline loss     95.84        92.89   \n",
      "3   DeBERTa-v3-base-document  contrastive loss     94.99        93.65   \n",
      "4        RadBERT-4m-document     baseline loss     95.86        93.65   \n",
      "5        RadBERT-4m-document  contrastive loss     95.73        96.07   \n",
      "\n",
      "   sensitivity     f1  \n",
      "0        96.89  96.87  \n",
      "1        95.87  96.76  \n",
      "2        97.08  97.05  \n",
      "3        95.55  96.41  \n",
      "4        96.79  97.05  \n",
      "5        95.59  96.92  \n",
      "\n",
      "Saved summary CSV to: trained_model_metrics\\summary_table.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "METRICS_DIR = \"trained_model_metrics\"\n",
    "OUT_CSV = os.path.join(METRICS_DIR, \"summary_table.csv\")\n",
    "\n",
    "def short_model_name(full_name: str) -> str:\n",
    "    \"\"\"Map HuggingFace model names to nice display names.\"\"\"\n",
    "    if \"Bio_ClinicalBERT\" in full_name:\n",
    "        return \"Bio_ClinicalBERT-document\"\n",
    "    if \"deberta-v3-base\" in full_name:\n",
    "        return \"DeBERTa-v3-base-document\"\n",
    "    if \"RadBERT-RoBERTa-4m\" in full_name:\n",
    "        return \"RadBERT-4m-document\"\n",
    "    # fallback\n",
    "    return full_name\n",
    "\n",
    "def load_and_augment(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Specificity = TN / (TN + FP)\n",
    "    df[\"specificity\"] = df[\"tn\"] / (df[\"tn\"] + df[\"fp\"])\n",
    "\n",
    "    # Sensitivity = recall (TP / (TP + FN))\n",
    "    df[\"sensitivity\"] = df[\"recall\"]\n",
    "\n",
    "    # Nice model + loss labels\n",
    "    df[\"Model\"] = df[\"model_name\"].apply(short_model_name)\n",
    "    df[\"Loss\"] = df[\"method\"].map({\n",
    "        \"Baseline\": \"baseline loss\",\n",
    "        \"Contrastive_Last_Layer\": \"contrastive loss\",\n",
    "    })\n",
    "\n",
    "    # Convert to percentages and round (like the paper)\n",
    "    for col in [\"accuracy\", \"specificity\", \"sensitivity\", \"f1\"]:\n",
    "        df[col] = (df[col] * 100).round(2)\n",
    "\n",
    "    return df[[\"Model\", \"Loss\", \"accuracy\", \"specificity\", \"sensitivity\", \"f1\"]]\n",
    "\n",
    "# ---------------------- main ---------------------- #\n",
    "all_dfs = []\n",
    "\n",
    "for path in glob.glob(os.path.join(METRICS_DIR, \"*_metrics.csv\")):\n",
    "    print(f\"Loading {path}...\")\n",
    "    all_dfs.append(load_and_augment(path))\n",
    "\n",
    "summary_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# Sort for a nice table order (optional)\n",
    "summary_df.sort_values([\"Model\", \"Loss\"], inplace=True)\n",
    "\n",
    "print(\"\\nSummary table:\")\n",
    "print(summary_df)\n",
    "\n",
    "summary_df.to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nSaved summary CSV to: {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8e52960-6d3e-45a6-ba6d-8e094c2d14da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bio_ClinicalBERT-document</td>\n",
       "      <td>baseline loss</td>\n",
       "      <td>95.59</td>\n",
       "      <td>92.52</td>\n",
       "      <td>96.89</td>\n",
       "      <td>96.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bio_ClinicalBERT-document</td>\n",
       "      <td>contrastive loss</td>\n",
       "      <td>95.48</td>\n",
       "      <td>94.56</td>\n",
       "      <td>95.87</td>\n",
       "      <td>96.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DeBERTa-v3-base-document</td>\n",
       "      <td>baseline loss</td>\n",
       "      <td>95.84</td>\n",
       "      <td>92.89</td>\n",
       "      <td>97.08</td>\n",
       "      <td>97.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeBERTa-v3-base-document</td>\n",
       "      <td>contrastive loss</td>\n",
       "      <td>94.99</td>\n",
       "      <td>93.65</td>\n",
       "      <td>95.55</td>\n",
       "      <td>96.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RadBERT-4m-document</td>\n",
       "      <td>baseline loss</td>\n",
       "      <td>95.86</td>\n",
       "      <td>93.65</td>\n",
       "      <td>96.79</td>\n",
       "      <td>97.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RadBERT-4m-document</td>\n",
       "      <td>contrastive loss</td>\n",
       "      <td>95.73</td>\n",
       "      <td>96.07</td>\n",
       "      <td>95.59</td>\n",
       "      <td>96.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model              Loss  accuracy  specificity  \\\n",
       "0  Bio_ClinicalBERT-document     baseline loss     95.59        92.52   \n",
       "1  Bio_ClinicalBERT-document  contrastive loss     95.48        94.56   \n",
       "2   DeBERTa-v3-base-document     baseline loss     95.84        92.89   \n",
       "3   DeBERTa-v3-base-document  contrastive loss     94.99        93.65   \n",
       "4        RadBERT-4m-document     baseline loss     95.86        93.65   \n",
       "5        RadBERT-4m-document  contrastive loss     95.73        96.07   \n",
       "\n",
       "   sensitivity     f1  \n",
       "0        96.89  96.87  \n",
       "1        95.87  96.76  \n",
       "2        97.08  97.05  \n",
       "3        95.55  96.41  \n",
       "4        96.79  97.05  \n",
       "5        95.59  96.92  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5fb2f6-e68a-4bf0-88f8-17773c9a2bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UV Radiology (.venv)",
   "language": "python",
   "name": "uv-radiology"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
