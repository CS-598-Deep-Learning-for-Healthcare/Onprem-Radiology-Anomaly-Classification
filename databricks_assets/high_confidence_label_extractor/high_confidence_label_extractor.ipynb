{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1009aab-ec32-4d4a-82d8-fb4f83d5a365",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the test tables\n",
    "test_tables = [\n",
    "    \"workspace.default.mimic_cxr_test_set_label_explanation_extract_databricks_qwen3_next_80b_a3b_instruct_v3\",\n",
    "    \"workspace.default.mimic_cxr_test_set_label_explanation_extract_gpt_5_1_v2\",\n",
    "    \"workspace.default.mimic_cxr_test_set_label_explanation_extract_llama_4_maverick_v1\",\n",
    "]\n",
    "\n",
    "# Define the train tables\n",
    "train_tables = [\n",
    "    \"workspace.default.mimic_cxr_train_set_label_explanation_extract_databricks_qwen3_next_80b_a3b_instruct_v3\",\n",
    "    \"workspace.default.mimic_cxr_train_set_label_explanation_extract_gpt_5_1_v2\",\n",
    "    \"workspace.default.mimic_cxr_train_set_label_explanation_extract_llama4_maverick_v1\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2623005-e448-4d24-8d75-52540610d813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "def build_consensus_dataset(table_names):\n",
    "    model_names = [\n",
    "        \"databricks_qwen3_next_80b_a3b_instruct_v3\",\n",
    "        \"gpt_5_1_v2\",\n",
    "        \"llama4_maverick_v1\",\n",
    "    ]\n",
    "\n",
    "    # 1) Load and union 3 model tables (include confidence)\n",
    "    dfs = []\n",
    "    for tbl, model in zip(table_names, model_names):\n",
    "        df = (\n",
    "            spark.table(tbl)\n",
    "                 .select(\n",
    "                     \"subject_id\",\n",
    "                     \"study_id\",\n",
    "                     \"findings\",\n",
    "                     \"impression\",\n",
    "                     \"label\",\n",
    "                     \"explanation\",\n",
    "                     \"confidence\",\n",
    "                 )\n",
    "                 .withColumn(\"model\", F.lit(model))\n",
    "        )\n",
    "        dfs.append(df)\n",
    "\n",
    "    union_df = dfs[0].unionByName(dfs[1]).unionByName(dfs[2])\n",
    "\n",
    "    # 2) Per (subject_id, study_id, label): count + avg(confidence)\n",
    "    label_stats = (\n",
    "        union_df\n",
    "        .groupBy(\"subject_id\", \"study_id\", \"label\")\n",
    "        .agg(\n",
    "            F.count(\"*\").alias(\"label_count\"),\n",
    "            F.avg(\"confidence\").alias(\"avg_conf\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 3) Per (subject_id, study_id): how many distinct labels\n",
    "    study_stats = (\n",
    "        label_stats\n",
    "        .groupBy(\"subject_id\", \"study_id\")\n",
    "        .agg(\n",
    "            F.count(\"*\").alias(\"num_labels\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    joined = label_stats.join(study_stats, on=[\"subject_id\", \"study_id\"], how=\"inner\")\n",
    "\n",
    "    # ---------- Unanimous case (all 3 labels same) ----------\n",
    "    unanimous = (\n",
    "        joined\n",
    "        .filter(F.col(\"num_labels\") == 1)\n",
    "        .select(\n",
    "            \"subject_id\",\n",
    "            \"study_id\",\n",
    "            F.col(\"label\").alias(\"consensus_label\"),\n",
    "            F.col(\"avg_conf\").alias(\"consensus_confidence\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ---------- Two-label cases: majority + higher avg confidence ----------\n",
    "    # Rank labels by count within each study\n",
    "    w = Window.partitionBy(\"subject_id\", \"study_id\").orderBy(F.col(\"label_count\").desc())\n",
    "\n",
    "    ranked = (\n",
    "        joined\n",
    "        .filter(F.col(\"num_labels\") == 2)\n",
    "        .withColumn(\"rank\", F.row_number().over(w))\n",
    "    )\n",
    "\n",
    "    # Majority (count 2) and minority (count 1)\n",
    "    majority = (\n",
    "        ranked\n",
    "        .filter(F.col(\"rank\") == 1)\n",
    "        .select(\n",
    "            \"subject_id\",\n",
    "            \"study_id\",\n",
    "            F.col(\"label\").alias(\"consensus_label\"),\n",
    "            F.col(\"avg_conf\").alias(\"majority_conf\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    minority = (\n",
    "        ranked\n",
    "        .filter(F.col(\"rank\") == 2)\n",
    "        .select(\n",
    "            \"subject_id\",\n",
    "            \"study_id\",\n",
    "            F.col(\"avg_conf\").alias(\"minority_conf\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Keep only if majority has higher avg confidence than minority\n",
    "    majority_kept = (\n",
    "        majority\n",
    "        .join(minority, on=[\"subject_id\", \"study_id\"], how=\"inner\")\n",
    "        .filter(F.col(\"majority_conf\") > F.col(\"minority_conf\"))\n",
    "        .select(\n",
    "            \"subject_id\",\n",
    "            \"study_id\",\n",
    "            \"consensus_label\",\n",
    "            F.col(\"majority_conf\").alias(\"consensus_confidence\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ---------- Combine unanimous + 2-vs-1 high-confidence ----------\n",
    "    consensus_labels = unanimous.unionByName(majority_kept)\n",
    "\n",
    "    # 4) Join back to get findings/impression/explanation\n",
    "    #    For explanation, just pick the first matching row per (subject, study)\n",
    "    winners = (\n",
    "        consensus_labels\n",
    "        .join(union_df, on=[\"subject_id\", \"study_id\"], how=\"inner\")\n",
    "        .where(F.col(\"label\") == F.col(\"consensus_label\"))\n",
    "    )\n",
    "\n",
    "    w2 = Window.partitionBy(\"subject_id\", \"study_id\").orderBy(\"model\")\n",
    "\n",
    "    final_df = (\n",
    "        winners\n",
    "        .withColumn(\"rn\", F.row_number().over(w2))\n",
    "        .filter(F.col(\"rn\") == 1)\n",
    "        .select(\n",
    "            \"subject_id\",\n",
    "            \"study_id\",\n",
    "            \"findings\",\n",
    "            \"impression\",\n",
    "            F.col(\"consensus_label\").alias(\"label\"),\n",
    "            \"explanation\",\n",
    "            F.col(\"consensus_confidence\").alias(\"confidence\"),\n",
    "        )\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53b1b599-fb48-42f8-95d2-8b0090fcafa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "consensus_train_df = build_consensus_dataset(train_tables)\n",
    "consensus_test_df  = build_consensus_dataset(test_tables)\n",
    "\n",
    "display(consensus_train_df.limit(10))\n",
    "display(consensus_test_df.limit(10))\n",
    "\n",
    "consensus_train_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"workspace.default.mimic_cxr_train_set_label_explanation_consensus_v1\")\n",
    "\n",
    "consensus_test_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"workspace.default.mimic_cxr_test_set_label_explanation_consensus_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f36b6500-595a-4126-b288-d53d74731f1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "consensus_train_df.printSchema()\n",
    "consensus_test_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43245893-003e-4095-9e4e-7a6246a57f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "high_confidence_label_extractor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
