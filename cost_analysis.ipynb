{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b70f5740-8066-4b52-883b-450b7dcd254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d827eeda-664a-4ea9-a50d-d81823c8a8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet('mimic_cxr_data/train-00000-of-00002.parquet')\n",
    "df2 = pd.read_parquet('mimic_cxr_data/train-00001-of-00002.parquet')\n",
    "\n",
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0ec3a8-74c5-43e1-870a-c42239508e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>findings</th>\n",
       "      <th>impression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>The lungs are clear of focal consolidation, pl...</td>\n",
       "      <td>No acute cardiopulmonary process.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>Lung volumes remain low. There are innumerable...</td>\n",
       "      <td>Low lung volumes and mild pulmonary vascular c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>Lung volumes are low. This results in crowding...</td>\n",
       "      <td>Innumerable pulmonary metastases. Possible mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>In comparison to study performed on of there i...</td>\n",
       "      <td>New mild pulmonary edema with persistent small...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>The right costophrenic angle is not imaged. Ot...</td>\n",
       "      <td>An enteric tube courses below the level of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15311</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>New collapse of the left upper lobe around a l...</td>\n",
       "      <td>New upper lobe collapse and some lower lobe at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15312</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>AP portable upright view of the chest. In this...</td>\n",
       "      <td>Improved aeration in the left upper lobe. Pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15313</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>The cardiomediastinal and hilar contours are w...</td>\n",
       "      <td>No acute cardiopulmonary process. No evidence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15314</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>The NG tube courses into the left upper abdom...</td>\n",
       "      <td>Appropriately positioned ET and NG tubes. Biba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15315</th>\n",
       "      <td>b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...</td>\n",
       "      <td>The NG tube courses below the diaphragm with ...</td>\n",
       "      <td>Slight interval worsening of right lower lung ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30633 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  \\\n",
       "0      b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "1      b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "2      b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "3      b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "4      b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "...                                                  ...   \n",
       "15311  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "15312  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "15313  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "15314  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "15315  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01...   \n",
       "\n",
       "                                                findings  \\\n",
       "0      The lungs are clear of focal consolidation, pl...   \n",
       "1      Lung volumes remain low. There are innumerable...   \n",
       "2      Lung volumes are low. This results in crowding...   \n",
       "3      In comparison to study performed on of there i...   \n",
       "4      The right costophrenic angle is not imaged. Ot...   \n",
       "...                                                  ...   \n",
       "15311  New collapse of the left upper lobe around a l...   \n",
       "15312  AP portable upright view of the chest. In this...   \n",
       "15313  The cardiomediastinal and hilar contours are w...   \n",
       "15314   The NG tube courses into the left upper abdom...   \n",
       "15315   The NG tube courses below the diaphragm with ...   \n",
       "\n",
       "                                              impression  \n",
       "0                      No acute cardiopulmonary process.  \n",
       "1      Low lung volumes and mild pulmonary vascular c...  \n",
       "2      Innumerable pulmonary metastases. Possible mil...  \n",
       "3      New mild pulmonary edema with persistent small...  \n",
       "4      An enteric tube courses below the level of the...  \n",
       "...                                                  ...  \n",
       "15311  New upper lobe collapse and some lower lobe at...  \n",
       "15312  Improved aeration in the left upper lobe. Pers...  \n",
       "15313  No acute cardiopulmonary process. No evidence ...  \n",
       "15314  Appropriately positioned ET and NG tubes. Biba...  \n",
       "15315  Slight interval worsening of right lower lung ...  \n",
       "\n",
       "[30633 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d048fd39-b0a3-4d62-ae6a-b3f0cd4f6a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The lungs are clear of focal consolidation, pleural effusion or pneumothorax. The heart size is normal. The mediastinal contours are normal. Multiple surgical clips project over the left breast, and old left rib fractures are noted. '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['findings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba4b73a-d307-469f-9f7f-15cb3528c278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No acute cardiopulmonary process.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['impression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a894c7f4-5afb-4658-a9f3-cf8028fddae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30633, 232160)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def count_sentences(text: str) -> int:\n",
    "    if not isinstance(text, str):\n",
    "        return 0\n",
    "    # very simple sentence split; same spirit as your script (split on \".\")\n",
    "    parts = re.split(r\"[.!?]\", text)\n",
    "    return sum(1 for p in parts if p.strip())\n",
    "\n",
    "def count_row_sentences(row):\n",
    "    findings = row.get(\"findings\", None)\n",
    "    impression = row.get(\"impression\", None)\n",
    "    text = \"\"\n",
    "    if isinstance(findings, str):\n",
    "        text += findings + \" \"\n",
    "    if isinstance(impression, str):\n",
    "        text += impression\n",
    "    return count_sentences(text)\n",
    "\n",
    "df[\"n_sentences\"] = df.apply(count_row_sentences, axis=1)\n",
    "total_sentences = int(df[\"n_sentences\"].sum())\n",
    "total_reports = len(df)\n",
    "\n",
    "total_reports, total_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc48f8d5-1295-442e-988d-ec08dcce7f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat_calls: 696480\n",
      "embedding_calls: 1392960\n",
      "total_requests: 2089440\n"
     ]
    }
   ],
   "source": [
    "S = total_sentences\n",
    "chat_calls = 3 * S\n",
    "embedding_calls = 6 * S\n",
    "total_requests = 9 * S\n",
    "\n",
    "print('chat_calls:', chat_calls)\n",
    "print('embedding_calls:', embedding_calls)\n",
    "print('total_requests:', total_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01b795d6-7b2d-4a9a-8144-0df441ea2d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(716.145, 71.01)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import tiktoken\n",
    "import re\n",
    "\n",
    "enc_chat = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "enc_emb = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "\n",
    "def build_query(sentence: str) -> str:\n",
    "    return f\"\"\"Use the below sentence to answer the subsequent question.\n",
    "    Emr_report:\n",
    "    \\\"\\\"\\\"\n",
    "    {sentence}\n",
    "    \\\"\\\"\\\"\n",
    "    Question: Does the patient have the specific disease in the chest based on the provied EMR report's sentence? \n",
    "    Answer form should be JSON object like following script. The JSON object has two key, \"Result\", and \"Explanation\".\n",
    "    For [Result], if the sentence doesn't have enough information or evidence to classify, you should return \"Uncertain\". \n",
    "    If the sentence has the clear evidence that indicates absence of any abnormalities in chest, you should answer \"No\". \n",
    "    If the sentence has the clear observational evidence that indicates presence of any abnormalities in chest (only for present), you should answer \"Yes\". \n",
    "\n",
    "    For [Explanation], you should give a sentence more than 40 letters and less than 60 letters which explain the reason about why you choose those answers. You should elucidating the rationale behind your choice, not a direct repetition, of the input text.\n",
    "    [Result] : Uncertain / No / Yes\n",
    "    \"\"\"\n",
    "\n",
    "def count_chat_tokens(sentence: str) -> int:\n",
    "    system = \"You will be provided with a emr sentecne.\"\n",
    "    user = build_query(sentence)\n",
    "    # simple chat token count approximation:\n",
    "    return len(enc_chat.encode(system)) + len(enc_chat.encode(user))\n",
    "\n",
    "def count_sentence_tokens(sentence: str) -> int:\n",
    "    return len(enc_emb.encode(sentence))\n",
    "\n",
    "# sample a bunch of sentences from df\n",
    "samples = []\n",
    "for _, row in df.sample(n=200, random_state=42).iterrows():\n",
    "    text = \"\"\n",
    "    if isinstance(row.get(\"findings\"), str):\n",
    "        text += row[\"findings\"] + \" \"\n",
    "    if isinstance(row.get(\"impression\"), str):\n",
    "        text += row[\"impression\"]\n",
    "    parts = [s.strip() for s in re.split(r\"[.!?]\", text) if s.strip()]\n",
    "    samples.extend(parts)\n",
    "\n",
    "samples = samples[:200]\n",
    "\n",
    "chat_tokens_per_call = sum(count_chat_tokens(s) for s in samples) / len(samples)\n",
    "embed_tokens_per_sentence = sum(count_sentence_tokens(s) for s in samples) / len(samples)\n",
    "\n",
    "chat_tokens_per_sentence_all_passes = chat_tokens_per_call * 3  # 3 passes\n",
    "embed_tokens_per_sentence_all_passes = (embed_tokens_per_sentence * 2) * 3  # ctx+explanation per pass, 3 passes\n",
    "\n",
    "chat_tokens_per_sentence_all_passes, embed_tokens_per_sentence_all_passes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e79d179-347c-4a45-b825-c2eeaa55a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_chat_tokens: 166260223.2\n",
      "total_embed_tokens: 16485681.600000001\n"
     ]
    }
   ],
   "source": [
    "total_chat_tokens = chat_tokens_per_sentence_all_passes * total_sentences\n",
    "total_embed_tokens = embed_tokens_per_sentence_all_passes * total_sentences\n",
    "\n",
    "print('total_chat_tokens:', total_chat_tokens)\n",
    "print('total_embed_tokens:', total_embed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a4805e-5a64-479d-a7b3-6c01747a44a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2026f727-7ec9-4d19-9b23-37259398e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences (S): 232836\n",
      "\n",
      "--- API CALLS ---\n",
      "Chat calls:       698,508\n",
      "Embedding calls:  1,397,016\n",
      "\n",
      "--- TOKENS ---\n",
      "Chat input tokens (total):        167,054,187\n",
      "Embedding input tokens (total):   36,514,470\n",
      "  - Context embeddings tokens:    8,574,150\n",
      "  - Explanation embeddings tokens (est): 27,940,320\n",
      "\n",
      "--- COST ESTIMATE ---\n",
      "Chat cost:        $8.35\n",
      "Embedding cost:   $4.75\n",
      "Total cost:       $13.10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG\n",
    "# -------------------------\n",
    "\n",
    "CHAT_MODEL = \"gpt-3.5-turbo\"\n",
    "EMBED_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "NUM_PASSES = 3  # how many GPT \"trials\" per sentence (your script uses 3)\n",
    "\n",
    "# pricing (you can tweak these)\n",
    "CHAT_COST_PER_M = 0.050    # $ per 1,000,000 input tokens\n",
    "EMB_COST_PER_K = 0.00013   # $ per 1,000 input tokens\n",
    "\n",
    "# estimated tokens in Explanation text (for embedding calls)\n",
    "# you can refine this later by sampling real outputs\n",
    "EXPLANATION_TOKENS_EST = 40\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# TOKENIZERS\n",
    "# -------------------------\n",
    "\n",
    "enc_chat = tiktoken.encoding_for_model(CHAT_MODEL)\n",
    "enc_emb = tiktoken.encoding_for_model(EMBED_MODEL)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# HELPERS\n",
    "# -------------------------\n",
    "\n",
    "def build_report_text(row) -> str:\n",
    "    \"\"\"Mirror get_report_text from your labeling script.\"\"\"\n",
    "    findings = row.get(\"findings\")\n",
    "    impression = row.get(\"impression\")\n",
    "\n",
    "    parts = []\n",
    "    if isinstance(findings, str) and findings.strip():\n",
    "        parts.append(findings.strip())\n",
    "    if isinstance(impression, str) and impression.strip():\n",
    "        parts.append(impression.strip())\n",
    "\n",
    "    return \". \".join(parts)\n",
    "\n",
    "\n",
    "def sentence_split(text: str):\n",
    "    \"\"\"Very simple splitter, similar to your script's text.split('.') logic.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    raw = re.split(r\"[.]\", text)\n",
    "    return [s.strip() for s in raw if s.strip()]\n",
    "\n",
    "\n",
    "def build_query(sentence: str) -> str:\n",
    "    \"\"\"Same query template used in your labeling code.\"\"\"\n",
    "    return f\"\"\"Use the below sentence to answer the subsequent question.\n",
    "    Emr_report:\n",
    "    \\\"\\\"\\\"\n",
    "    {sentence}\n",
    "    \\\"\\\"\\\"\n",
    "    Question: Does the patient have the specific disease in the chest based on the provied EMR report's sentence? \n",
    "    Answer form should be JSON object like following script. The JSON object has two key, \"Result\", and \"Explanation\".\n",
    "    For [Result], if the sentence doesn't have enough information or evidence to classify, you should return \"Uncertain\". \n",
    "    If the sentence has the clear evidence that indicates absence of any abnormalities in chest, you should answer \"No\". \n",
    "    If the sentence has the clear observational evidence that indicates presence of any abnormalities in chest (only for present), you should answer \"Yes\". \n",
    "\n",
    "    For [Explanation], you should give a sentence more than 40 letters and less than 60 letters which explain the reason about why you choose those answers. You should elucidating the rationale behind your choice, not a direct repetition, of the input text.\n",
    "    [Result] : Uncertain / No / Yes\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def chat_input_tokens_for_sentence(sentence: str) -> int:\n",
    "    system_msg = \"You will be provided with a emr sentecne.\"\n",
    "    user_msg = build_query(sentence)\n",
    "    return len(enc_chat.encode(system_msg)) + len(enc_chat.encode(user_msg))\n",
    "\n",
    "\n",
    "def embedding_tokens_for_context(sentence: str) -> int:\n",
    "    cleaned = sentence.replace(\"\\n\", \" \")\n",
    "    return len(enc_emb.encode(cleaned))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# MAIN TOKEN + COST ESTIMATION\n",
    "# -------------------------\n",
    "\n",
    "all_sentences = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    text = build_report_text(row)\n",
    "    sents = sentence_split(text)\n",
    "    all_sentences.extend(sents)\n",
    "\n",
    "S = len(all_sentences)\n",
    "print(f\"Total sentences (S): {S}\")\n",
    "\n",
    "chat_tokens_total = 0\n",
    "emb_context_tokens_total = 0\n",
    "\n",
    "for sent in all_sentences:\n",
    "    chat_tok = chat_input_tokens_for_sentence(sent)\n",
    "    emb_ctx_tok = embedding_tokens_for_context(sent)\n",
    "\n",
    "    # per sentence across all passes\n",
    "    chat_tokens_total += NUM_PASSES * chat_tok\n",
    "    emb_context_tokens_total += NUM_PASSES * emb_ctx_tok\n",
    "\n",
    "# explanation embedding tokens: estimated\n",
    "emb_expl_tokens_total = NUM_PASSES * S * EXPLANATION_TOKENS_EST\n",
    "\n",
    "emb_tokens_total = emb_context_tokens_total + emb_expl_tokens_total\n",
    "\n",
    "# API calls\n",
    "chat_calls = NUM_PASSES * S\n",
    "embedding_calls = NUM_PASSES * 2 * S  # context + explanation per pass\n",
    "\n",
    "# costs\n",
    "chat_cost = (chat_tokens_total / 1_000_000) * CHAT_COST_PER_M\n",
    "emb_cost = (emb_tokens_total / 1_000) * EMB_COST_PER_K\n",
    "total_cost = chat_cost + emb_cost\n",
    "\n",
    "print(\"\\n--- API CALLS ---\")\n",
    "print(f\"Chat calls:       {chat_calls:,}\")\n",
    "print(f\"Embedding calls:  {embedding_calls:,}\")\n",
    "\n",
    "print(\"\\n--- TOKENS ---\")\n",
    "print(f\"Chat input tokens (total):        {chat_tokens_total:,}\")\n",
    "print(f\"Embedding input tokens (total):   {emb_tokens_total:,}\")\n",
    "print(f\"  - Context embeddings tokens:    {emb_context_tokens_total:,}\")\n",
    "print(f\"  - Explanation embeddings tokens (est): {emb_expl_tokens_total:,}\")\n",
    "\n",
    "print(\"\\n--- COST ESTIMATE ---\")\n",
    "print(f\"Chat cost:        ${chat_cost:,.2f}\")\n",
    "print(f\"Embedding cost:   ${emb_cost:,.2f}\")\n",
    "print(f\"Total cost:       ${total_cost:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481fa6ee-9ccb-4122-9c8b-3b0bc76573c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UV Radiology (.venv)",
   "language": "python",
   "name": "uv-radiology"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
